#!/usr/bin/env -S uv run
"""Stub generation processor for creating type stub files."""

import ast
import re
from pathlib import Path
from typing import ClassVar

from ..config import StubConfig
from ..core.config import StubGenConfig
from ..errors import ErrorCode, StubGenerationError
from ..types.type_system import TypeRegistry
from ..utils.ast_utils import attach_parents


class StubGenerator:
    """Generate type stubs from Python source code."""

    # Common import patterns to preserve
    ESSENTIAL_IMPORTS: ClassVar[set[str]] = {
        "typing",
        "dataclasses",
        "enum",
        "abc",
        "contextlib",
        "pathlib",
        "collections.abc",
    }

    def __init__(
        self,
        config: StubConfig | StubGenConfig | None = None,
        type_registry: TypeRegistry | None = None,
    ) -> None:
        """Initialize the stub generator.

        Args:
            config: Configuration for stub generation
            type_registry: Registry for type resolution
        """
        if isinstance(config, StubGenConfig):
            # Create a StubConfig from StubGenConfig
            self.config = StubConfig(
                input_path=Path("."),  # Temporary path, will be set per file
                output_path=None,  # Will be set per file
                line_length=88,
                sort_imports=True,
                add_header=True,
                include_private=config.processing.include_private,
                include_type_comments=config.processing.include_type_comments,
                infer_property_types=config.processing.infer_property_types,
                export_less=config.processing.export_less,
                docstring_type_hints=config.processing.include_docstrings,
                backend="ast",
                parallel=True,
                max_workers=None,
                infer_types=True,
                preserve_literals=False,
                no_import=False,
                inspect=False,
                doc_dir="",
                ignore_errors=True,
                parse_only=False,
                verbose=False,
                quiet=True,
                max_docstring_length=150,
            )
        else:
            # Use provided config or create default
            self.config = config or StubConfig(
                input_path=Path("."),
                output_path=None,
                backend="ast",
                parallel=True,
                max_workers=None,
                infer_types=True,
                preserve_literals=False,
                docstring_type_hints=True,
                line_length=88,
                sort_imports=True,
                add_header=True,
                no_import=False,
                inspect=False,
                doc_dir="",
                ignore_errors=True,
                parse_only=False,
                include_private=False,
                verbose=False,
                quiet=True,
                export_less=False,
                max_docstring_length=150,
                include_type_comments=True,
                infer_property_types=True,
            )
        self.type_registry = type_registry or TypeRegistry()

    def generate_stub(self, source_path: Path, tree: ast.AST | None = None) -> str:
        """Generate a type stub for a Python source file.

        Args:
            source_path: Path to the source file
            tree: Optional pre-parsed AST

        Returns:
            Generated stub content

        Raises:
            StubGenerationError: If stub generation fails
        """
        try:
            # Parse source if not provided
            if tree is None:
                with source_path.open() as f:
                    tree = ast.parse(f.read(), filename=str(source_path))

            # Attach parent references for better context
            attach_parents(tree)

            # Process the AST
            if not isinstance(tree, ast.Module):
                raise StubGenerationError(
                    "Expected Module AST node",
                    ErrorCode.AST_PARSE_ERROR,
                    source=str(source_path),
                )

            # Generate stub content
            lines = []

            # Add header if configured
            if self.config.add_header:
                lines.extend(
                    [
                        '"""# Generated by pystubnik',
                        "# Do not edit this file directly",
                        '"""',
                        "",
                    ]
                )

            # Process imports
            imports = []
            for child in tree.body:
                if isinstance(
                    child, ast.Import | ast.ImportFrom
                ) and self._should_keep_import(child):
                    if isinstance(child, ast.ImportFrom):
                        module = child.module or ""
                        names = sorted(n.name for n in child.names)
                        if module == "typing":
                            imports.append(
                                ("typing", f"from typing import {', '.join(names)}")
                            )
                        elif module == "pathlib":
                            imports.append(
                                ("pathlib", f"from pathlib import {', '.join(names)}")
                            )
                        elif module.startswith("."):
                            imports.append(
                                ("local", f"from {module} import {', '.join(names)}")
                            )
                        elif module in self.ESSENTIAL_IMPORTS:
                            imports.append(
                                ("stdlib", f"from {module} import {', '.join(names)}")
                            )
                        else:
                            imports.append(
                                (
                                    "third_party",
                                    f"from {module} import {', '.join(names)}",
                                )
                            )
                    else:
                        names = sorted(n.name for n in child.names)
                        name = names[0].split(".")[0]
                        if name in self.ESSENTIAL_IMPORTS:
                            imports.append(("stdlib", f"import {', '.join(names)}"))
                        else:
                            imports.append(
                                ("third_party", f"import {', '.join(names)}")
                            )

            # Sort imports by type and then alphabetically
            imports.sort(
                key=lambda x: (
                    {
                        "stdlib": 0,
                        "pathlib": 1,
                        "typing": 2,
                        "third_party": 3,
                        "local": 4,
                    }[x[0]],
                    x[1],
                )
            )

            # Group imports by type
            current_type = None
            for imp_type, imp_str in imports:
                if current_type is not None and current_type != imp_type:
                    lines.append("")
                current_type = imp_type
                lines.append(imp_str)

            # Add blank line after imports if there are any
            if imports:
                lines.append("")

            # Process definitions
            for child in tree.body:
                if isinstance(child, ast.ClassDef):
                    # Skip private classes if configured
                    if not self.config.include_private and child.name.startswith("_"):
                        continue
                    lines.extend(self._process_class_to_lines(child))
                elif isinstance(child, ast.FunctionDef):
                    # Skip private functions (but keep __init__ and special methods)
                    if not self.config.include_private and child.name.startswith("_"):
                        if not (child.name.startswith("__") and child.name.endswith("__")):
                            if child.name != "__init__":
                                continue
                    lines.extend(self._process_function_to_lines(child))
                elif isinstance(child, ast.Assign | ast.AnnAssign):
                    if line := self._process_assignment_to_line(child):
                        lines.append(line)

            # Join lines and return
            stub = "\n".join(lines)

            # Fix spacing in function arguments and assignments
            stub = re.sub(r"([^=])=([^=])", r"\1 = \2", stub)
            stub = stub.replace("  = ", " = ")

            return stub

        except Exception as e:
            raise StubGenerationError(
                f"Failed to generate stub for {source_path}: {e}",
                ErrorCode.AST_TRANSFORM_ERROR,
                source=str(source_path),
            ) from e

    def _process_class_to_lines(self, node: ast.ClassDef) -> list[str]:
        """Process a class definition to lines.

        Args:
            node: Class definition AST node

        Returns:
            List of lines for the stub
        """
        lines = []

        # Skip private classes
        if not self.config.include_private and node.name.startswith("_"):
            if not (node.name.startswith("__") and node.name.endswith("__")):
                return []

        # Extract docstring if present
        if (
            node.body
            and isinstance(node.body[0], ast.Expr)
            and isinstance(node.body[0].value, (ast.Str, ast.Constant))
            and isinstance(node.body[0].value.value, str)
        ):
            docstring = node.body[0].value.value
            lines.append(f'"""{docstring}"""')

        # Add class definition
        bases = ", ".join(ast.unparse(base) for base in node.bases)
        if bases:
            lines.append(f"class {node.name}({bases}):")
        else:
            lines.append(f"class {node.name}:")

        # Process class body
        body_lines = []
        for child in node.body:
            if isinstance(child, ast.FunctionDef):
                # Skip private methods (but keep __init__ and special methods)
                if not self.config.include_private and child.name.startswith("_"):
                    if not (child.name.startswith("__") and child.name.endswith("__")):
                        if child.name != "__init__":
                            continue
                body_lines.extend(self._process_function_to_lines(child))
            elif isinstance(child, ast.Assign | ast.AnnAssign):
                if line := self._process_assignment_to_line(child):
                    body_lines.append(line)

        # Add body lines with indentation
        if body_lines:
            lines.extend("    " + line for line in body_lines)
        else:
            lines.append("    pass")

        return lines

    def _process_function_to_lines(self, node: ast.FunctionDef) -> list[str]:
        """Process a function definition to lines.

        Args:
            node: Function definition node

        Returns:
            List of lines for the function definition
        """
        lines = []

        # Add docstring if present
        if (
            len(node.body) > 0
            and isinstance(node.body[0], ast.Expr)
            and isinstance(
                node.body[0].value, ast.Constant | ast.Str
            )  # Support both old and new AST
        ):
            docstring = node.body[0].value.value
            lines.append(f'"""{docstring}"""')

        # Add function definition
        args = ast.unparse(node.args)
        returns = f" -> {ast.unparse(node.returns)}" if node.returns else ""
        lines.append(f"def {node.name}({args}){returns}:")
        lines.append("    pass")

        return lines

    def _process_assignment_to_line(
        self, node: ast.Assign | ast.AnnAssign
    ) -> str | None:
        """Process an assignment to a line.

        Args:
            node: Assignment node

        Returns:
            Line for the assignment or None if it should be excluded
        """
        match node:
            case ast.AnnAssign():
                # Preserve annotated assignments
                return ast.unparse(node)
            case ast.Assign(
                targets=[ast.Name() as name_node], value=ast.Constant() as value
            ):
                # Only keep module-level assignments of constants
                if not name_node.id.startswith("_") or name_node.id.isupper():
                    return f"{name_node.id}: {type(value.value).__name__} = {ast.unparse(value)}"
        return None

    def _should_keep_import(self, node: ast.Import | ast.ImportFrom) -> bool:
        """Check if an import should be kept in the stub.

        Args:
            node: Import node to check

        Returns:
            True if the import should be kept
        """
        if isinstance(node, ast.ImportFrom):
            return node.module in self.ESSENTIAL_IMPORTS or any(
                name.name.isupper() for name in node.names
            )
        return any(
            name.name in self.ESSENTIAL_IMPORTS
            or name.name.split(".")[0] in self.ESSENTIAL_IMPORTS
            for name in node.names
        )

    def _import_sort_key(self, node: ast.Import | ast.ImportFrom) -> tuple[int, str]:
        """Get sort key for import statements.

        Args:
            node: Import node to sort

        Returns:
            Tuple of (import type, module name) for sorting
        """
        if isinstance(node, ast.ImportFrom):
            return (1, node.module or "")
        return (0, node.names[0].name)

    def _ensure_node_attributes(self, node: ast.AST) -> None:
        """Ensure AST nodes have required attributes for unparsing.

        Args:
            node: AST node to process
        """
        # Add required attributes if missing
        for attr, default in [
            ("lineno", 0),
            ("col_offset", 0),
            ("end_lineno", 0),
            ("end_col_offset", 0),
        ]:
            if not hasattr(node, attr):
                setattr(node, attr, default)

        # Process child nodes
        for child in ast.iter_child_nodes(node):
            self._ensure_node_attributes(child)

    def _generate_content(self, node: ast.Module) -> str:
        """Generate stub content from AST.

        Args:
            node: AST to generate content from

        Returns:
            Generated stub content
        """
        # Add header if configured
        header = (
            '"""# Generated by pystubnik\n# Do not edit this file directly\n\n"""\n'
            if self.config.add_header
            else ""
        )

        # Convert AST to source code
        source = ast.unparse(node)

        # Fix spacing in function arguments and assignments
        source = source.replace("=", " = ")
        source = source.replace("  =  ", " = ")

        # Fix docstring formatting
        source = source.replace("'''", '"""')
        source = source.replace('""""""', '"""')

        # Add header and return
        return header + source

    def _collect_imports(self, node: ast.Module) -> list[ast.stmt]:
        """Collect and process import statements.

        Args:
            node: Module AST to process

        Returns:
            List of processed import statements
        """
        imports = [
            child
            for child in node.body
            if isinstance(child, ast.Import | ast.ImportFrom)
            and self._should_keep_import(child)
        ]

        if self.config.sort_imports and imports:
            # Convert imports to strings for easier sorting
            import_lines = []
            for imp in imports:
                if isinstance(imp, ast.ImportFrom):
                    module = imp.module or ""
                    names = sorted(n.name for n in imp.names)
                    if module == "typing":
                        import_lines.append(
                            ("typing", f"from typing import {', '.join(names)}")
                        )
                    elif module == "pathlib":
                        import_lines.append(
                            ("pathlib", f"from pathlib import {', '.join(names)}")
                        )
                    elif module.startswith("."):
                        import_lines.append(
                            ("local", f"from {module} import {', '.join(names)}")
                        )
                    elif module in self.ESSENTIAL_IMPORTS:
                        import_lines.append(
                            ("stdlib", f"from {module} import {', '.join(names)}")
                        )
                    else:
                        import_lines.append(
                            ("third_party", f"from {module} import {', '.join(names)}")
                        )
                else:
                    names = sorted(n.name for n in imp.names)
                    name = names[0].split(".")[0]
                    if name in self.ESSENTIAL_IMPORTS:
                        import_lines.append(("stdlib", f"import {', '.join(names)}"))
                    else:
                        import_lines.append(
                            ("third_party", f"import {', '.join(names)}")
                        )

            # Sort imports by type and then alphabetically
            import_lines.sort(
                key=lambda x: (
                    {
                        "stdlib": 0,
                        "pathlib": 1,
                        "typing": 2,
                        "third_party": 3,
                        "local": 4,
                    }[x[0]],
                    x[1],
                )
            )

            # Convert back to AST nodes
            result: list[ast.stmt] = []
            current_type = None
            for imp_type, imp_str in import_lines:
                if current_type is not None and current_type != imp_type:
                    result.append(ast.Expr(value=ast.Constant(value="\n")))
                current_type = imp_type
                result.extend(ast.parse(imp_str).body)

            return result

        return list(imports)  # Convert to list[ast.stmt]
